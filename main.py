import streamlit as st
import pandas as pd
import numpy as np
import joblib
import re
from sklearn.linear_model import LinearRegression
from difflib import SequenceMatcher
import random
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="é’¢æ¿åˆ’ç—•é£é™©é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜
st.title("ğŸ›¡ï¸ é’¢æ¿åˆ’ç—•é£é™©é¢„æµ‹ä¸ä¼˜åŒ–ç³»ç»Ÿ")
st.markdown("é€šè¿‡é€‰æ‹©é’¢æ¿å‚æ•°å’ŒåŠ å·¥è®¾å¤‡ï¼Œé¢„æµ‹åˆ’ç—•é£é™©å¹¶è·å–ä¼˜åŒ–å»ºè®®")


# åŠ è½½æ¨¡å‹
@st.cache_resource
def load_model():
    try:
        with st.spinner("æ­£åœ¨åŠ è½½é¢„æµ‹æ¨¡å‹..."):
            # è¯·å°†æ¨¡å‹è·¯å¾„æ›¿æ¢ä¸ºæ‚¨çš„å®é™…æ¨¡å‹è·¯å¾„
            model_data = joblib.load("ä¼˜åŒ–åPLS_RFæœ€ä¼˜æ¨¡å‹.pkl")

            # éªŒè¯æ¨¡å‹ç»„ä»¶
            required_components = ['model', 'encoder_pls', 'pls_model', 'encoder_other',
                                   'feature_names', 'train_proc', 'best_pls_components']
            missing_components = [comp for comp in required_components if comp not in model_data]
            if missing_components:
                st.error(f"æ¨¡å‹ç¼ºå°‘å…³é”®ç»„ä»¶: {missing_components}")
                return None

            st.success("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            return model_data
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return None


# æ•°æ®è½¬æ¢å‡½æ•°
def convert_scratch_resistance(value):
    if pd.isna(value):
        return np.nan
    if isinstance(value, str):
        value = value.strip().replace('N', '').replace('ç‰›é¡¿', '')
        numbers = re.findall(r'\d+\.?\d*', value)
        if numbers:
            val = np.mean([float(num) for num in numbers])
            return max(0.5, val)
        return np.nan
    val = float(value)
    return max(0.5, val)


def unify_gloss_format(value):
    if pd.isna(value):
        return np.nan
    value = str(value).strip().lower()
    text_map = {'ä½å…‰æ³½': 5, 'ä¸­å…‰æ³½': 20, 'é«˜å…‰æ³½': 40,
                'low': 5, 'medium': 20, 'high': 40,
                'ä½': 5, 'ä¸­': 20, 'é«˜': 40}
    if value in text_map:
        return text_map[value]
    nums = re.findall(r'\d+\.?\d*', value)
    if nums:
        val = float(nums[0])
        return max(0, min(100, val))
    return np.nan


# é¢„å¤„ç†å‡½æ•°
def preprocess_data(input_data, model_data):
    df = pd.DataFrame([input_data])

    # å¤„ç†æ•°å€¼ç‰¹å¾
    df['è€åˆ’ç—•æ ‡å‡†'] = df['è€åˆ’ç—•æ ‡å‡†'].apply(convert_scratch_resistance)
    df['å…‰æ³½åº¦'] = df['å…‰æ³½åº¦'].apply(unify_gloss_format)

    # å¡«å……ç©ºå€¼
    train_proc = model_data['train_proc']
    fill_values = {
        'è€åˆ’ç—•æ ‡å‡†': train_proc['è€åˆ’ç—•æ ‡å‡†'].median(),
        'å…‰æ³½åº¦': train_proc['å…‰æ³½åº¦'].median()
    }
    for col, fill_val in fill_values.items():
        df[col].fillna(fill_val, inplace=True)

    # å¤„ç†åˆ†ç±»ç‰¹å¾
    category_cols = ['é’¢æ¿ç±»å‹', 'é¢œè‰²æ·±æµ…åº¦']
    train_categories = {
        col: set(train_proc[col].astype(str).str.strip().str.replace(' ', '').str.replace('-', '').str.lower())
        for col in category_cols
    }

    for col in category_cols:
        df[col] = df[col].astype(str).str.strip().str.replace(' ', '').str.replace('-', '').str.lower()
        unknown_cats = set(df[col].unique()) - train_categories[col]
        if unknown_cats:
            df[col] = df[col].apply(lambda x: 'å…¶ä»–' if x in unknown_cats else x)

    # å¤„ç†è®¾å¤‡ç±»å‹
    equipment_cols = ['å¼€æ–™è®¾å¤‡', 'å°è¾¹è®¾å¤‡', 'æ‰“å­”è®¾å¤‡']
    train_equipment = {
        col: set(train_proc[col].astype(str).str.strip().str.replace(' ', '').str.replace('-', '').str.lower())
        for col in equipment_cols
    }

    for col in equipment_cols:
        df[col] = df[col].astype(str).str.strip().str.replace(' ', '').str.replace('-', '').str.lower()

        unknown_equipment = set(df[col].unique()) - train_equipment[col]
        if unknown_equipment:
            fuzzy_matches = {}
            for unknown in unknown_equipment:
                max_similarity = 0
                best_match = None
                for train_eq in train_equipment[col]:
                    sim = SequenceMatcher(None, unknown, train_eq).ratio()
                    if sim > max_similarity and sim > 0.6:
                        max_similarity = sim
                        best_match = train_eq
                if best_match:
                    fuzzy_matches[unknown] = best_match

            for unknown, train_eq in fuzzy_matches.items():
                df[col] = df[col].replace(unknown, train_eq)

            remaining_unknown = set(df[col].unique()) - train_equipment[col]
            if remaining_unknown:
                df[col] = df[col].apply(lambda x: 'å…¶ä»–' if x in remaining_unknown else x)

    # åˆ›å»ºè®¾å¤‡ç»„åˆç‰¹å¾
    df['å¼€æ–™-å°è¾¹ç»„åˆ'] = df['å¼€æ–™è®¾å¤‡'] + "_" + df['å°è¾¹è®¾å¤‡']

    return df


# ç”Ÿæˆç‰¹å¾å‡½æ•°
def generate_features(preprocessed_data, model_data):
    coupled_cols = ['é’¢æ¿ç±»å‹', 'é¢œè‰²æ·±æµ…åº¦', 'å…‰æ³½åº¦']
    X_pls = model_data['encoder_pls'].transform(preprocessed_data[coupled_cols])
    pls_features = model_data['pls_model'].transform(X_pls)
    pls_cols = [f'pls_{i + 1}' for i in range(pls_features.shape[1])]
    pls_df = pd.DataFrame(pls_features, columns=pls_cols)

    other_cols = ['å¼€æ–™è®¾å¤‡', 'å°è¾¹è®¾å¤‡', 'æ‰“å­”è®¾å¤‡', 'å¼€æ–™-å°è¾¹ç»„åˆ', 'è€åˆ’ç—•æ ‡å‡†']
    X_other = model_data['encoder_other'].transform(preprocessed_data[other_cols])
    other_feature_names = model_data['encoder_other'].get_feature_names_out(other_cols)
    other_df = pd.DataFrame(X_other, columns=other_feature_names)

    sample_features = pd.concat([pls_df, other_df], axis=1)
    missing_features = [col for col in model_data['feature_names'] if col not in sample_features.columns]
    for col in missing_features:
        sample_features[col] = 0

    return sample_features[model_data['feature_names']]


# åˆ†æè®¾å¤‡æ€§èƒ½
def analyze_equipment_performance(model_data):
    train_proc = model_data['train_proc']
    analysis = {}

    # å•è®¾å¤‡æ€§èƒ½åˆ†æ
    for col in ['å¼€æ–™è®¾å¤‡', 'å°è¾¹è®¾å¤‡', 'æ‰“å­”è®¾å¤‡']:
        eq_risk = train_proc.groupby(col, observed=True).agg({
            'åˆ’ç—•é£é™©æ¦‚ç‡': ['mean', 'count']
        }).round(6)
        eq_risk.columns = ['å¹³å‡é£é™©', 'æ ·æœ¬æ•°']
        analysis[col] = eq_risk[eq_risk['æ ·æœ¬æ•°'] >= 2].sort_values('å¹³å‡é£é™©')

    # è®¾å¤‡ç»„åˆåˆ†æ
    combo_risk = train_proc.groupby('å¼€æ–™-å°è¾¹ç»„åˆ', observed=True).agg({
        'åˆ’ç—•é£é™©æ¦‚ç‡': ['mean', 'count']
    }).round(6)
    combo_risk.columns = ['å¹³å‡é£é™©', 'æ ·æœ¬æ•°']
    analysis['è®¾å¤‡ç»„åˆ'] = combo_risk[combo_risk['æ ·æœ¬æ•°'] >= 3].sort_values('å¹³å‡é£é™©')

    # é¢œè‰²æ·±æµ…åº¦ä¸é£é™©å…³ç³»
    color_risk = train_proc.groupby('é¢œè‰²æ·±æµ…åº¦', observed=True).agg({
        'åˆ’ç—•é£é™©æ¦‚ç‡': ['mean', 'count']
    }).round(6)
    color_risk.columns = ['å¹³å‡é£é™©', 'æ ·æœ¬æ•°']
    analysis['é¢œè‰²æ·±æµ…åº¦'] = color_risk[color_risk['æ ·æœ¬æ•°'] >= 2].sort_values('å¹³å‡é£é™©')

    # è€åˆ’ç—•æ ‡å‡†ä¸é£é™©å…³ç³»
    scratch_risk = train_proc.groupby(pd.cut(train_proc['è€åˆ’ç—•æ ‡å‡†'], bins=5), observed=True).agg({
        'åˆ’ç—•é£é™©æ¦‚ç‡': 'mean'
    }).round(6)
    scratch_risk.columns = ['å¹³å‡é£é™©']
    analysis['è€åˆ’ç—•æ ‡å‡†'] = scratch_risk

    return analysis


# ç”Ÿæˆä¼˜åŒ–å»ºè®®
def generate_optimization_suggestions(input_data, current_risk, model_data):
    analysis = analyze_equipment_performance(model_data)
    suggestions = []
    used_equipment = {'å¼€æ–™è®¾å¤‡': [], 'å°è¾¹è®¾å¤‡': [], 'æ‰“å­”è®¾å¤‡': [], 'å¼€æ–™-å°è¾¹ç»„åˆ': []}

    # ç¡®å®šé£é™©ç­‰çº§
    if current_risk >= 0.003:
        risk_level = "é«˜é£é™©"
        target_reduction = 0.4
    elif current_risk >= 0.001:
        risk_level = "ä¸­é£é™©"
        target_reduction = 0.3
    else:
        risk_level = "ä½é£é™©"
        target_reduction = 0.1

    target_risk = current_risk * (1 - target_reduction)

    # 1. è®¾å¤‡ç»„åˆä¼˜åŒ–å»ºè®®
    current_combo = f"{input_data['å¼€æ–™è®¾å¤‡']}_{input_data['å°è¾¹è®¾å¤‡']}"
    if current_combo in analysis['è®¾å¤‡ç»„åˆ'].index:
        current_combo_risk = analysis['è®¾å¤‡ç»„åˆ'].loc[current_combo, 'å¹³å‡é£é™©']
        better_combos = analysis['è®¾å¤‡ç»„åˆ'][analysis['è®¾å¤‡ç»„åˆ']['å¹³å‡é£é™©'] < current_combo_risk]

        if not better_combos.empty:
            # ä¼˜å…ˆé€‰æ‹©æœªæ¨èè¿‡çš„ç»„åˆ
            unused_combos = [combo for combo in better_combos.index
                             if combo not in used_equipment['å¼€æ–™-å°è¾¹ç»„åˆ']]

            if unused_combos:
                best_combo = unused_combos[0]
            else:
                best_combo = better_combos.index[0]

            # æ›´æ–°å†å²è®°å½•
            used_equipment['å¼€æ–™-å°è¾¹ç»„åˆ'].append(best_combo)
            if len(used_equipment['å¼€æ–™-å°è¾¹ç»„åˆ']) > 10:
                used_equipment['å¼€æ–™-å°è¾¹ç»„åˆ'].pop(0)

            reduction = ((current_combo_risk - better_combos.loc[best_combo, 'å¹³å‡é£é™©'])
                         / current_combo_risk * 100)
            suggestions.append({
                "priority": 1,
                "desc": f"ä¼˜åŒ–è®¾å¤‡ç»„åˆï¼š{current_combo} â†’ {best_combo}ï¼ˆé¢„è®¡é™ä½é£é™©{reduction:.1f}%ï¼‰",
                "type": "è®¾å¤‡ç»„åˆä¼˜åŒ–"
            })

    # 2. å•è®¾å¤‡ä¼˜åŒ–å»ºè®®
    for eq_type in ['å¼€æ–™è®¾å¤‡', 'å°è¾¹è®¾å¤‡']:
        current_eq = input_data[eq_type]
        if current_eq in analysis[eq_type].index:
            current_eq_risk = analysis[eq_type].loc[current_eq, 'å¹³å‡é£é™©']
            better_eq = analysis[eq_type][analysis[eq_type]['å¹³å‡é£é™©'] < current_eq_risk]

            if not better_eq.empty:
                # ä¼˜å…ˆé€‰æ‹©æœªæ¨èè¿‡çš„è®¾å¤‡
                unused_eq = [eq for eq in better_eq.index if eq not in used_equipment[eq_type]]

                if unused_eq:
                    best_eq = unused_eq[0]
                else:
                    best_eq = better_eq.index[0]

                # æ›´æ–°å†å²è®°å½•
                used_equipment[eq_type].append(best_eq)
                if len(used_equipment[eq_type]) > 10:
                    used_equipment[eq_type].pop(0)

                reduction = ((current_eq_risk - better_eq.loc[best_eq, 'å¹³å‡é£é™©'])
                             / current_eq_risk * 100)
                suggestions.append({
                    "priority": 2,
                    "desc": f"æ›´æ¢{eq_type}ï¼š{current_eq} â†’ {best_eq}ï¼ˆé¢„è®¡é™ä½é£é™©{reduction:.1f}%ï¼‰",
                    "type": f"{eq_type}ä¼˜åŒ–"
                })

    # 3. é¢œè‰²è°ƒæ•´å»ºè®®
    current_color = input_data['é¢œè‰²æ·±æµ…åº¦']
    if current_color in analysis['é¢œè‰²æ·±æµ…åº¦'].index:
        current_color_risk = analysis['é¢œè‰²æ·±æµ…åº¦'].loc[current_color, 'å¹³å‡é£é™©']
        better_colors = analysis['é¢œè‰²æ·±æµ…åº¦'][analysis['é¢œè‰²æ·±æµ…åº¦']['å¹³å‡é£é™©'] < current_color_risk]

        if not better_colors.empty:
            best_color = better_colors.index[0]
            reduction = ((current_color_risk - better_colors.loc[best_color, 'å¹³å‡é£é™©'])
                         / current_color_risk * 100)
            suggestions.append({
                "priority": 2,
                "desc": f"è°ƒæ•´é¢œè‰²æ·±æµ…åº¦ï¼š{current_color} â†’ {best_color}ï¼ˆé¢„è®¡é™ä½é£é™©{reduction:.1f}%ï¼‰",
                "type": "é¢œè‰²ä¼˜åŒ–"
            })

    # 4. è€åˆ’ç—•æ ‡å‡†ä¼˜åŒ–å»ºè®®
    current_scratch = input_data['è€åˆ’ç—•æ ‡å‡†']
    target_scratch = current_scratch * (1 + min(target_reduction * 2, 0.5))  # é€‚åº¦æé«˜
    suggestions.append({
        "priority": 3,
        "desc": f"æé«˜è€åˆ’ç—•æ ‡å‡†ï¼š{current_scratch:.1f}N â†’ {target_scratch:.1f}Nï¼ˆé¢„è®¡é™ä½é£é™©{target_reduction * 100:.0f}%ï¼‰",
        "type": "è€åˆ’ç—•æ ‡å‡†ä¼˜åŒ–"
    })

    # æŒ‰ä¼˜å…ˆçº§æ’åºå»ºè®®
    suggestions.sort(key=lambda x: x["priority"])

    # æ ¹æ®é£é™©ç­‰çº§é€‰æ‹©é€‚å½“æ•°é‡çš„å»ºè®®
    if risk_level == "é«˜é£é™©":
        selected_suggestions = suggestions[:3]
    elif risk_level == "ä¸­é£é™©":
        selected_suggestions = suggestions[:2]
    else:
        selected_suggestions = suggestions[:1]

    return selected_suggestions, target_risk


# é¢„æµ‹å‡½æ•°
def predict_risk(input_data, model_data):
    try:
        # é¢„å¤„ç†æ•°æ®
        preprocessed_data = preprocess_data(input_data, model_data)

        # ç”Ÿæˆç‰¹å¾
        features = generate_features(preprocessed_data, model_data)

        # é¢„æµ‹é£é™©
        risk_probability = model_data['model'].predict(features)[0]

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        suggestions, optimized_risk = generate_optimization_suggestions(
            input_data, risk_probability, model_data)

        return {
            "success": True,
            "risk_probability": risk_probability,
            "suggestions": suggestions,
            "optimized_risk": optimized_risk
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


# ä¸»å‡½æ•°
def main():
    # åŠ è½½æ¨¡å‹
    model_data = load_model()
    if model_data is None:
        return

    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns([1, 2])

    with col1:
        st.sidebar.header("å‚æ•°è®¾ç½®")

        # 1. é’¢æ¿ç±»å‹
        steel_type = st.sidebar.selectbox(
            "1. é’¢æ¿ç±»å‹",
            options=["å¸ƒçº¹", "é’ˆç»‡å¸ƒçº¹", "æ–¹æ ¼é¢", "é«˜ä½å…‰", "è”æçš®çº¹", "é›¶åº¦æ‰‹æŠ“çº¹",
                     "é›¶åº¦ç»†ç›´çº¹", "é›¶åº¦å°æœ¨åˆº", "é›¶åº¦é›¨ä¸çº¹", "ç»’éº»é¢", "æ²™è´é¢",
                     "ç»†éº»é¢", "ç»†ä¸çº¹"]
        )

        # 2. å…‰æ³½åº¦
        gloss = st.sidebar.slider(
            "2. å…‰æ³½åº¦ï¼ˆæ•°å€¼è¶Šé«˜å…‰æ³½è¶Šå¼ºï¼‰",
            min_value=5,
            max_value=40,
            step=5,
            value=20,
            help="ä½å…‰æ³½ï¼š5ï¼Œä¸­å…‰æ³½ï¼š20ï¼Œé«˜å…‰æ³½ï¼š40"
        )

        # 3. é¢œè‰²æ·±æµ…åº¦
        color_depth = st.sidebar.radio(
            "3. é¢œè‰²æ·±æµ…åº¦",
            options=["æµ…è‰²", "ä¸­è‰²", "æ·±è‰²"],
            horizontal=True
        )

        # 4. è€åˆ’ç—•æ ‡å‡†
        scratch_resistance = st.sidebar.number_input(
            "4. è€åˆ’ç—•æ ‡å‡†ï¼ˆå•ä½ï¼šNï¼‰",
            min_value=1.0,
            max_value=10.0,
            value=3.0,
            step=0.5,
            help="å¸¸è§å€¼ï¼š3Nï¼ˆåŸºç¡€ï¼‰ã€5Nï¼ˆä¸­ç­‰ï¼‰ã€7Nï¼ˆé«˜è€åˆ®ï¼‰"
        )

        # 5. å¼€æ–™è®¾å¤‡
        cutting_machine = st.sidebar.selectbox(
            "5. å¼€æ–™è®¾å¤‡",
            options=["å¥—é“£", "å—å…´380ç”µå­æ®", "è±ªè¿ˆ380ç”µå­é”¯", "è±ªè¿ˆ300ç”µå­æ®",
                     "è°¢æ—ç”µå­é”¯", "æ¨å°é”¯", "æåŠ¨ç”µå­æ®", "å—å…´å¤§æ¿å¥—é“£",
                     "æ¬§ç™»å¤šç²¾å¯†æ¨å°é”¯", "é©¬æ°ç²¾å¯†æ¨å°é”¯", "é¼åŠ›åŠ å·¥ä¸­å¿ƒ", "å…¶ä»–"]
        )

        # 6. å°è¾¹è®¾å¤‡
        edge_banding_machine = st.sidebar.selectbox(
            "6. å°è¾¹è®¾å¤‡",
            options=["KAL610å°è¾¹æœº", "NKL210å°è¾¹æœº", "è±ªè¿ˆ210å°è¾¹æœº", "è±ªè¿ˆ350å°è¾¹æœº",
                     "å—å…´å°è¾¹æœº", "åŒ…è¦†æœº", "æä¸œ668Jå°è¾¹æœº", "æä¸œè‡ªåŠ¨å°è¾¹æœº",
                     "å—å…´è‡ªåŠ¨å°è¾¹æœº", "å—å…´é«˜é€Ÿè‡ªåŠ¨å°è¾¹æœº", "å…¶ä»–"]
        )

        # 7. æ‰“å­”è®¾å¤‡
        drilling_machine = st.sidebar.selectbox(
            "7. æ‰“å­”è®¾å¤‡",
            options=["T-E9SL", "KN-2309P", "æä¸œ2309", "è±ªè¿ˆè‡ªåŠ¨æ‰“å­”æœº",
                     "æ‹“é›•å•é€šé“å…­é¢é’»", "ä¿Šé©­é—¨é“°æœº", "é©¬æ°é’»å­”æœº", "å—å…´å…­é¢é’»",
                     "é¼åŠ›è®¾å¤‡", "æä¸œæ•°æ§é’»å­”ä¸­å¿ƒ", "å…¶ä»–"]
        )

        # é¢„æµ‹æŒ‰é’®
        predict_button = st.sidebar.button("é¢„æµ‹é£é™©", key="predict", use_container_width=True)

    with col2:
        # æ˜¾ç¤ºè¾“å…¥å‚æ•°æ‘˜è¦
        st.subheader("å‚æ•°æ‘˜è¦")
        input_data = {
            "é’¢æ¿ç±»å‹": steel_type,
            "å…‰æ³½åº¦": gloss,
            "é¢œè‰²æ·±æµ…åº¦": color_depth,
            "è€åˆ’ç—•æ ‡å‡†": scratch_resistance,
            "å¼€æ–™è®¾å¤‡": cutting_machine,
            "å°è¾¹è®¾å¤‡": edge_banding_machine,
            "æ‰“å­”è®¾å¤‡": drilling_machine
        }

        # ä»¥è¡¨æ ¼å½¢å¼å±•ç¤ºå‚æ•°
        param_df = pd.DataFrame(list(input_data.items()), columns=["å‚æ•°", "å€¼"])
        st.dataframe(param_df, use_container_width=True, hide_index=True)

        # é¢„æµ‹ç»“æœå±•ç¤º
        if predict_button:
            with st.spinner("æ­£åœ¨é¢„æµ‹é£é™©å¹¶ç”Ÿæˆä¼˜åŒ–å»ºè®®..."):
                result = predict_risk(input_data, model_data)

                if result["success"]:
                    # æ˜¾ç¤ºåŸå§‹é£é™©
                    st.subheader("ğŸ“Š é£é™©é¢„æµ‹ç»“æœ")

                    # é£é™©ç­‰çº§åˆ¤æ–­
                    risk_prob = result["risk_probability"]
                    if risk_prob >= 0.003:
                        risk_level = "é«˜é£é™©"
                        risk_color = "red"
                    elif risk_prob >= 0.001:
                        risk_level = "ä¸­é£é™©"
                        risk_color = "orange"
                    else:
                        risk_level = "ä½é£é™©"
                        risk_color = "green"

                    # æ˜¾ç¤ºé£é™©å€¼å’Œç­‰çº§
                    col_risk1, col_risk2 = st.columns(2)
                    with col_risk1:
                        st.metric(
                            label="é¢„æµ‹åˆ’ç—•é£é™©æ¦‚ç‡",
                            value=f"{risk_prob:.6f}",
                            delta="",
                            delta_color="inverse"
                        )
                    with col_risk2:
                        st.markdown(
                            f"**é£é™©ç­‰çº§**: <span style='color:{risk_color};font-size:1.2em'>{risk_level}</span>",
                            unsafe_allow_html=True)

                    # å¯è§†åŒ–é£é™©
                    fig, ax = plt.subplots(figsize=(8, 2))
                    ax.barh(["é£é™©æ¦‚ç‡"], [risk_prob], color=risk_color, height=0.5)
                    ax.set_xlim(0, max(0.005, risk_prob * 1.5))
                    ax.set_xlabel('é£é™©æ¦‚ç‡')
                    ax.grid(axis='x', linestyle='--', alpha=0.7)
                    st.pyplot(fig)

                    # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
                    st.subheader("ğŸ’¡ ä¼˜åŒ–å»ºè®®")
                    suggestions = result["suggestions"]

                    for i, suggestion in enumerate(suggestions, 1):
                        with st.expander(f"å»ºè®® #{i}: {suggestion['type']}", expanded=True):
                            st.info(suggestion["desc"])

                    # æ˜¾ç¤ºä¼˜åŒ–åé£é™©
                    st.subheader("âœ¨ ä¼˜åŒ–åé¢„æœŸæ•ˆæœ")
                    optimized_risk = result["optimized_risk"]

                    # ä¼˜åŒ–åé£é™©ç­‰çº§
                    if optimized_risk >= 0.003:
                        optimized_level = "ä»ä¸ºé«˜é£é™©"
                        optimized_color = "red"
                    elif optimized_risk >= 0.001:
                        optimized_level = "é™è‡³ä¸­é£é™©"
                        optimized_color = "orange"
                    else:
                        optimized_level = "é™è‡³ä½é£é™©"
                        optimized_color = "green"

                    # è®¡ç®—é£é™©é™ä½ç™¾åˆ†æ¯”
                    risk_reduction = ((risk_prob - optimized_risk) / risk_prob) * 100

                    col_opt1, col_opt2, col_opt3 = st.columns(3)
                    with col_opt1:
                        st.metric(
                            label="ä¼˜åŒ–åé£é™©æ¦‚ç‡",
                            value=f"{optimized_risk:.6f}",
                            delta=f"{risk_reduction:.2f}%",
                            delta_color="normal"
                        )
                    with col_opt2:
                        st.markdown(
                            f"**ä¼˜åŒ–åç­‰çº§**: <span style='color:{optimized_color};font-size:1.2em'>{optimized_level}</span>",
                            unsafe_allow_html=True)
                    with col_opt3:
                        st.metric(
                            label="é£é™©é™ä½å¹…åº¦",
                            value=f"{risk_reduction:.2f}%",
                            delta="",
                            delta_color="normal"
                        )

                    # ä¼˜åŒ–å‰åå¯¹æ¯”å›¾
                    fig, ax = plt.subplots(figsize=(8, 3))
                    bars = ax.bar(["ä¼˜åŒ–å‰", "ä¼˜åŒ–å"], [risk_prob, optimized_risk],
                                  color=[risk_color, optimized_color], width=0.6)
                    ax.set_ylim(0, max(0.005, risk_prob * 1.5))
                    ax.set_ylabel('é£é™©æ¦‚ç‡')
                    ax.grid(axis='y', linestyle='--', alpha=0.7)

                    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
                    for bar in bars:
                        height = bar.get_height()
                        ax.text(bar.get_x() + bar.get_width() / 2., height,
                                f'{height:.6f}',
                                ha='center', va='bottom')

                    st.pyplot(fig)
                else:
                    st.error(f"é¢„æµ‹å¤±è´¥: {result['error']}")


if __name__ == "__main__":
    main()
